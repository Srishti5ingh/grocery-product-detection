{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GroceryDataset_Inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff49c2a5bb6044ce9326ae866c763f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_184e9c6d05b942dcb39c0c97cd5ce1c9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2e8ca943aa3d419cbc821841bafb667e",
              "IPY_MODEL_bd332aee8c1343bbb0a4ed127c3214a4",
              "IPY_MODEL_b79e69c0de734661b6fd1f1389e88538"
            ]
          }
        },
        "184e9c6d05b942dcb39c0c97cd5ce1c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e8ca943aa3d419cbc821841bafb667e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_104c824613c34240a327dc1f63fd5b3a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_edf9ba62a4fa450dbf78c675d2411a55"
          }
        },
        "bd332aee8c1343bbb0a4ed127c3214a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7107a5f7a1c847c2a834e96ca46b16bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 71,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 71,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ae34a0060e24d7e8c1fa40613ef7a59"
          }
        },
        "b79e69c0de734661b6fd1f1389e88538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f7b8e72c03af411698bb76b1dee5d98e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 71/71 [01:42&lt;00:00,  1.23s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cbc9fa58b194e4f9aacf348b086c684"
          }
        },
        "104c824613c34240a327dc1f63fd5b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "edf9ba62a4fa450dbf78c675d2411a55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7107a5f7a1c847c2a834e96ca46b16bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ae34a0060e24d7e8c1fa40613ef7a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7b8e72c03af411698bb76b1dee5d98e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cbc9fa58b194e4f9aacf348b086c684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGYQ6RL0f7ST"
      },
      "source": [
        "This notebooks takes the model trained in `Colabs/grocery-dataset-model-training.ipynb` notebook and runs inference with it to determine how many products are likely to be present inside a given shelf image. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBLZjxZLgP3u"
      },
      "source": [
        "## Inital setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NqU2APeK22f",
        "outputId": "325c363d-a3a9-4af6-885d-bee48578c683"
      },
      "source": [
        "# Which GPU?\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 15 05:34:14 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd4NZAq7LeH0",
        "outputId": "e4a648e1-efc6-4dd4-dba2-cfb64a1909c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install TFOD API (TF 1)\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf \n",
        "print(tf.__version__)\n",
        "\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "% cd models/research\n",
        "!pip install --upgrade pip\n",
        "# Compile protos.\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf1/setup.py .\n",
        "!python -m pip install --use-feature=2020-resolver ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 62663, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 62663 (delta 18), reused 53 (delta 14), pack-reused 62604\u001b[K\n",
            "Receiving objects: 100% (62663/62663), 574.53 MiB | 29.78 MiB/s, done.\n",
            "Resolving deltas: 100% (43653/43653), done.\n",
            "/content/models/research\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.2.4-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.2.4\n",
            "\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n",
            "Processing /content/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.24)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1665130 sha256=f3f19c3b77adc4dc1eb2b0c9dfec18b654a6d51e0d5e74eb9a1cc2811fb50fb8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xmoebv32/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "Successfully built object-detection\n",
            "Installing collected packages: tf-slim, lvis, object-detection\n",
            "Successfully installed lvis-0.5.3 object-detection-0.1 tf-slim-1.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWprg3OxgS7o"
      },
      "source": [
        "## Gather trained model and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qim1npNwMqkC",
        "outputId": "35bf4cb6-756c-4253-af10-898c745e445e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLYYyLh1Mt6e",
        "outputId": "87328508-4be4-4727-944c-072696722ee7"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/product-detection/fp32/*.pb .\n",
        "!ls -lh *.pb"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 26M Sep 15 05:37 frozen_inference_graph.pb\n",
            "-rw------- 1 root root 28M Sep 15 05:37 tflite_graph.pb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJp4Z1IINvUq"
      },
      "source": [
        "!wget -q https://storage.googleapis.com/open_source_datasets/ShelfImages.tar.gz\n",
        "!tar xf ShelfImages.tar.gz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6HgPU9HNx7X",
        "outputId": "e78c8113-745c-4cb5-c655-a4b5c52c8115"
      },
      "source": [
        "!ls -lh ShelfImages/test | head -10"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 101M\n",
            "-rw-r--r-- 1 1001 1001 1.6M Oct 23  2019 C1_P02_N1_S5_1.JPG\n",
            "-rw-r--r-- 1 1001 1001 2.3M Oct 23  2019 C1_P02_N2_S2_1.JPG\n",
            "-rw-r--r-- 1 1001 1001 2.3M Oct 23  2019 C1_P02_N2_S3_1.JPG\n",
            "-rw-r--r-- 1 1001 1001 1.3M Oct 23  2019 C1_P03_N1_S2_1.JPG\n",
            "-rw-r--r-- 1 1001 1001 1.6M Oct 23  2019 C1_P03_N1_S3_1.JPG\n",
            "-rw-r--r-- 1 1001 1001 2.4M Oct 23  2019 C1_P03_N1_S4_1.JPG\n",
            "-rw-r--r-- 1 1001 1001 1.4M Oct 23  2019 C1_P03_N1_S4_2.JPG\n",
            "-rw-r--r-- 1 1001 1001 1.1M Oct 23  2019 C1_P03_N2_S2_1.JPG\n",
            "-rw-r--r-- 1 1001 1001 1.7M Oct 23  2019 C1_P03_N2_S3_1.JPG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnDZPmbYgXOo"
      },
      "source": [
        "## Other imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75QByXOZN2Ea"
      },
      "source": [
        "from imutils import paths\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j007Jtg-gZ1C"
      },
      "source": [
        "## Image parsing utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuDYf5L8T9QU"
      },
      "source": [
        "def parse_image(image_path: str) -> np.ndarray:\n",
        "    \"\"\"Reads an image and adds a batch dimension.\"\"\"\n",
        "    image = plt.imread(image_path).astype(np.uint8)\n",
        "    image = np.expand_dims(image, 0)\n",
        "    return image"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4t2CTblgxJX"
      },
      "source": [
        "## Load test image paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlUGjLG8PWOD",
        "outputId": "85c59353-e337-4a65-f12f-e51fe67f4d83"
      },
      "source": [
        "test_image_paths = list(paths.list_images(\"ShelfImages/test\"))\n",
        "test_image_paths[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ShelfImages/test/C2_P07_N2_S2_1.JPG',\n",
              " 'ShelfImages/test/C3_P05_N3_S2_1.JPG',\n",
              " 'ShelfImages/test/C1_P05_N4_S3_1.JPG',\n",
              " 'ShelfImages/test/C4_P02_N4_S2_1.JPG',\n",
              " 'ShelfImages/test/C3_P04_N1_S5_1.JPG']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi4aiGlxgzOZ"
      },
      "source": [
        "## Load detection graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lK3FyaXOSx5"
      },
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(\"frozen_inference_graph.pb\", \"rb\") as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VKMB60rhbit"
      },
      "source": [
        "## Inference utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMKP9-KaPNzf"
      },
      "source": [
        "def run_inference_for_single_image(image, graph, min_threshold=0.6):\n",
        "    \"\"\"Runs detection graph on an image and parses the results.\"\"\"\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                \"num_detections\", \"detection_boxes\", \"detection_scores\",\n",
        "                \"detection_classes\"]:\n",
        "                tensor_name = key + \":0\"\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "                image_tensor = tf.get_default_graph().get_tensor_by_name(\"image_tensor:0\")\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                    feed_dict={image_tensor: image})\n",
        "\n",
        "    # Post-process the results\n",
        "    output_dict[\"detection_scores\"] = output_dict[\"detection_scores\"][0]\n",
        "    mask = output_dict[\"detection_scores\"] > min_threshold\n",
        "\n",
        "    return output_dict[\"detection_scores\"][mask]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4m2vMjZhelj"
      },
      "source": [
        "## Run bulk inference and prepare JSON file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ff49c2a5bb6044ce9326ae866c763f2f",
            "184e9c6d05b942dcb39c0c97cd5ce1c9",
            "2e8ca943aa3d419cbc821841bafb667e",
            "bd332aee8c1343bbb0a4ed127c3214a4",
            "b79e69c0de734661b6fd1f1389e88538",
            "104c824613c34240a327dc1f63fd5b3a",
            "edf9ba62a4fa450dbf78c675d2411a55",
            "7107a5f7a1c847c2a834e96ca46b16bc",
            "5ae34a0060e24d7e8c1fa40613ef7a59",
            "f7b8e72c03af411698bb76b1dee5d98e",
            "4cbc9fa58b194e4f9aacf348b086c684"
          ]
        },
        "id": "m2n5B338eFOM",
        "outputId": "0c8d28cb-dd38-4bc9-bc93-e1f6dcf1168d"
      },
      "source": [
        "image_to_products = {}\n",
        "for image_path in tqdm(test_image_paths):\n",
        "    image_name = image_path.split(\"/\")[-1]\n",
        "    image = parse_image(image_path)\n",
        "    num_products = len(run_inference_for_single_image(image, detection_graph))\n",
        "    image_to_products[image_name] = num_products\n",
        "\n",
        "json_string = json.dumps(image_to_products, indent=4) \n",
        "with open(\"image2products.json\", \"w\") as outfile: \n",
        "    outfile.write(json_string) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff49c2a5bb6044ce9326ae866c763f2f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/71 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEFRMvyF-gco",
        "outputId": "d7e6c9a2-2e9e-4776-dde1-02090da57fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkBhSZZ3fhyY",
        "outputId": "c16304f5-03a1-4fa3-90cc-901e3e1d6e60"
      },
      "source": [
        "!head -10 image2products.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"C2_P03_N2_S3_1.JPG\": 22,\n",
            "    \"C1_P10_N1_S5_1.JPG\": 51,\n",
            "    \"C3_P01_N2_S3_2.JPG\": 17,\n",
            "    \"C4_P03_N1_S3_1.JPG\": 33,\n",
            "    \"C2_P04_N3_S2_1.JPG\": 21,\n",
            "    \"C3_P03_N2_S4_1.JPG\": 49,\n",
            "    \"C3_P04_N1_S5_1.JPG\": 40,\n",
            "    \"C4_P08_N2_S2_1.JPG\": 24,\n",
            "    \"C4_P03_N1_S4_1.JPG\": 45,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C62tMvqf0hb"
      },
      "source": [
        "## References\n",
        "* https://github.com/anirbankonar123/CorrosionDetector/blob/master/rust_localization.ipynb"
      ]
    }
  ]
}