{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GroceryDataset_Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2N7NkgwwY0J"
      },
      "source": [
        "This notebook generates recall and precision scores (for 0.5IOU) on the test grocery dataset with the model trained in `Colabs/GroceryDataset_Model_Training.ipynb` notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhEPQw5DwpOi"
      },
      "source": [
        "## Initial setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NODfSF7_tSup",
        "outputId": "031760cf-6c80-4166-a629-2a1c0e6d920b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install TFOD API (TF 1)\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf \n",
        "print(tf.__version__)\n",
        "\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "% cd models/research\n",
        "!pip install --upgrade pip\n",
        "# Compile protos.\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf1/setup.py .\n",
        "!python -m pip install --use-feature=2020-resolver ."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 62654, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 62654 (delta 14), reused 46 (delta 12), pack-reused 62604\u001b[K\n",
            "Receiving objects: 100% (62654/62654), 574.53 MiB | 31.82 MiB/s, done.\n",
            "Resolving deltas: 100% (43649/43649), done.\n",
            "/content/models/research\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.2.4-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 15.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.2.4\n",
            "\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n",
            "Processing /content/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.24)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1665130 sha256=98f814ae3ba79087735c8f06ea9782f33ce14270b62829eaddb2d9bc1f99603a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0o2t014_/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "Successfully built object-detection\n",
            "Installing collected packages: tf-slim, lvis, object-detection\n",
            "Successfully installed lvis-0.5.3 object-detection-0.1 tf-slim-1.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1-24eTVwrIl"
      },
      "source": [
        "## Gather test record file, trained model graph and `.pbtxt`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmKymBcZtZCJ",
        "outputId": "9ea47992-5841-42fd-9982-541c34a920ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqpDHUi8tc8N"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/product-detection2/test.record .\n",
        "!cp -r /content/drive/MyDrive/product-detection2/label_map.pbtxt .\n",
        "!cp -r /content/drive/MyDrive/product-detection2/fp32/frozen_inference_graph.pb ."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUxSjOu3wx8S"
      },
      "source": [
        "## Gather detections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ryXl_Z1uDmf",
        "outputId": "a1f3b425-206e-4297-a193-42406f910f11"
      },
      "source": [
        "# Infer detections on a TFRecord of TFExamples given an inference graph.\n",
        "!python /content/models/research/object_detection/inference/infer_detections.py \\\n",
        "    --input_tfrecord_paths=test.record \\\n",
        "    --output_tfrecord_path=detections.tfrecord \\\n",
        "    --inference_graph=frozen_inference_graph.pb"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-09-14 22:12:23.990482: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-09-14 22:12:23.990550: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ab49426b9cda): /proc/driver/nvidia/version does not exist\n",
            "INFO:tensorflow:Reading input from 1 files\n",
            "I0914 22:12:24.059536 139663807170432 infer_detections.py:68] Reading input from 1 files\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/inference/detection_inference.py:35: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "W0914 22:12:24.060024 139663807170432 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/object_detection/inference/detection_inference.py:35: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "W0914 22:12:24.086953 139663807170432 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
            "W0914 22:12:24.087338 139663807170432 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:112: BaseResourceVariable.count_up_to (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Dataset.range instead.\n",
            "W0914 22:12:24.093722 139663807170432 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:112: BaseResourceVariable.count_up_to (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Dataset.range instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0914 22:12:24.095628 139663807170432 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0914 22:12:24.096321 139663807170432 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/inference/detection_inference.py:37: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
            "W0914 22:12:24.098826 139663807170432 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/object_detection/inference/detection_inference.py:37: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
            "INFO:tensorflow:Reading graph and building model...\n",
            "I0914 22:12:24.110233 139663807170432 infer_detections.py:71] Reading graph and building model...\n",
            "INFO:tensorflow:Running inference and writing output to detections.tfrecord\n",
            "I0914 22:12:24.996775 139663807170432 infer_detections.py:77] Running inference and writing output to detections.tfrecord\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/infer_detections.py:79: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0914 22:12:25.192606 139663807170432 deprecation.py:345] From /content/models/research/object_detection/inference/infer_detections.py:79: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Processed 0 images...\n",
            "I0914 22:12:25.193742 139663807170432 infer_detections.py:85] Processed 0 images...\n",
            "INFO:tensorflow:Processed 10 images...\n",
            "I0914 22:12:27.936697 139663807170432 infer_detections.py:85] Processed 10 images...\n",
            "INFO:tensorflow:Processed 20 images...\n",
            "I0914 22:12:29.759884 139663807170432 infer_detections.py:85] Processed 20 images...\n",
            "INFO:tensorflow:Processed 30 images...\n",
            "I0914 22:12:31.499000 139663807170432 infer_detections.py:85] Processed 30 images...\n",
            "INFO:tensorflow:Processed 40 images...\n",
            "I0914 22:12:32.973147 139663807170432 infer_detections.py:85] Processed 40 images...\n",
            "INFO:tensorflow:Processed 50 images...\n",
            "I0914 22:12:34.598515 139663807170432 infer_detections.py:85] Processed 50 images...\n",
            "INFO:tensorflow:Processed 60 images...\n",
            "I0914 22:12:36.354744 139663807170432 infer_detections.py:85] Processed 60 images...\n",
            "INFO:tensorflow:Processed 70 images...\n",
            "I0914 22:12:37.808964 139663807170432 infer_detections.py:85] Processed 70 images...\n",
            "INFO:tensorflow:Finished processing records\n",
            "I0914 22:12:37.993118 139663807170432 infer_detections.py:92] Finished processing records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y21jZm5xw0DR"
      },
      "source": [
        "## Generate metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16wWX30MujMg",
        "outputId": "440cb402-407a-48b0-a906-0d53ce62b94c"
      },
      "source": [
        "!git clone https://github.com/svpino/tf_object_detection_cm"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tf_object_detection_cm'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 35 (delta 0), reused 3 (delta 0), pack-reused 31\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQS10XALux3H",
        "outputId": "f3ef5206-a1a7-4fde-88ad-39ad023b1861"
      },
      "source": [
        "!python tf_object_detection_cm/confusion_matrix.py \\\n",
        "    --detections_record=detections.tfrecord \\\n",
        "    --label_map=label_map.pbtxt \\\n",
        "    --output_path=confusion_matrix.csv"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-09-14 22:16:57.272102: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-09-14 22:16:57.272168: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ab49426b9cda): /proc/driver/nvidia/version does not exist\n",
            "WARNING:tensorflow:From tf_object_detection_cm/confusion_matrix.py:39: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "W0914 22:16:57.273885 140262804522880 deprecation.py:345] From tf_object_detection_cm/confusion_matrix.py:39: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "Processed 71 images\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1.964e+03 0.000e+00 8.000e+00 0.000e+00 2.000e+00 1.000e+00 1.300e+01\n",
            "  7.000e+00 3.000e+00 0.000e+00 1.000e+00 2.400e+01]\n",
            " [0.000e+00 4.700e+01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
            " [2.900e+01 0.000e+00 2.200e+02 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 3.000e+00]\n",
            " [6.000e+00 0.000e+00 0.000e+00 1.000e+01 0.000e+00 0.000e+00 0.000e+00\n",
            "  3.000e+00 0.000e+00 0.000e+00 0.000e+00 2.000e+00]\n",
            " [6.000e+00 0.000e+00 0.000e+00 0.000e+00 8.900e+01 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
            " [1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 2.200e+01 0.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00]\n",
            " [9.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 4.100e+01\n",
            "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 2.000e+00]\n",
            " [4.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  7.500e+01 0.000e+00 0.000e+00 0.000e+00 2.000e+00]\n",
            " [4.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 2.800e+01 0.000e+00 0.000e+00 0.000e+00]\n",
            " [1.000e+01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 2.000e+00 0.000e+00 0.000e+00]\n",
            " [5.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00 4.000e+00 0.000e+00]\n",
            " [6.100e+01 0.000e+00 1.100e+01 6.000e+00 7.000e+00 2.000e+00 7.000e+00\n",
            "  2.000e+01 1.000e+00 6.000e+00 1.000e+00 0.000e+00]] \n",
            "\n",
            "   category  ...  recall_@0.5IOU\n",
            "0         1  ...        0.970835\n",
            "1         2  ...        1.000000\n",
            "2         5  ...        0.936842\n",
            "3         8  ...        0.925926\n",
            "4         4  ...        0.476190\n",
            "5         7  ...        0.788462\n",
            "6        11  ...        0.444444\n",
            "7         3  ...        0.873016\n",
            "8         6  ...        0.916667\n",
            "9         9  ...        0.875000\n",
            "10       10  ...        0.166667\n",
            "\n",
            "[11 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeDwMqTwXvgd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}